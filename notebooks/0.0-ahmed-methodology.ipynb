{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe255624",
   "metadata": {},
   "source": [
    "# Data Pipeline Methodology\n",
    "\n",
    "> Ahmed Hasan (7932883) \u2014 COMP 4710 Group 11, Winnipeg PTN Analysis\n",
    "\n",
    "This notebook documents data sources, architecture, validation checks, and frequency-analysis outputs from the project DuckDB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e47b52",
   "metadata": {},
   "source": [
    "## 1) Data Sources\n",
    "\n",
    "| Source Category | Dataset / Feed | ID | Purpose | Access |\n",
    "|---|---|---|---|---|\n",
    "| GTFS (Current) | Winnipeg Transit GTFS zip | n/a | Base schedule network (stops, routes, trips, stop_times, shapes, calendars) | https://gtfs.winnipegtransit.com/google_transit.zip |\n",
    "| GTFS (Historical) | Transitland feed versions | n/a | Pre/post PTN comparison when available | https://www.transit.land/terms |\n",
    "| Winnipeg Open Data | Neighbourhoods | `8k6x-xxsy` | Coverage boundaries | https://data.winnipeg.ca |\n",
    "| Winnipeg Open Data | Community Areas | `gfvw-fk34` | Coarser aggregation boundaries | https://data.winnipeg.ca |\n",
    "| Winnipeg Open Data | Cycling Network | `kjd9-dvf5` | Active mobility context | https://data.winnipeg.ca |\n",
    "| Winnipeg Open Data | Pass-ups | `mer2-irmb` | Service quality events | https://data.winnipeg.ca |\n",
    "| Winnipeg Open Data | On-time Performance | `gp3k-am4u` | Deviation/reliability analysis | https://data.winnipeg.ca |\n",
    "| Winnipeg Open Data | Passenger Counts | `bv6q-du26` | Ridership proxy | https://data.winnipeg.ca |\n",
    "\n",
    "PTN launch date: **June 29, 2025**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a469cd7",
   "metadata": {},
   "source": [
    "## 2) Technology Stack\n",
    "\n",
    "| Component | Role in Project |\n",
    "|---|---|\n",
    "| DuckDB | Embedded analytical database for storage, SQL transforms, and querying |\n",
    "| DuckDB Spatial extension | Geospatial SQL operations |\n",
    "| NetworkX | Graph analytics on transit network edges/stops |\n",
    "| `gtfs-kit` | GTFS feed/service-date utilities |\n",
    "| `gtfs-functions` | GTFS helper workflows |\n",
    "| `pandera` | Data validation |\n",
    "| `keplergl` | Interactive map visualization (downstream) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f884a",
   "metadata": {},
   "source": [
    "## 3) Pipeline Architecture\n",
    "\n",
    "1. **Ingest**: Download GTFS + Open Data into `data/raw/`.\n",
    "2. **Load**: Materialize raw tables in DuckDB (`raw_gtfs_*`, `raw_open_data_*`, boundaries).\n",
    "3. **Transform (SQL-first)**: Build `agg_*`, `ref_*`, `v_*` via SQL scripts under `ptn_analysis/data/sql/`.\n",
    "4. **Consume**: Analysis modules read raw/agg/ref/view tables.\n",
    "\n",
    "Primary command: `make data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27359b",
   "metadata": {},
   "source": [
    "## 4) Setup\n",
    "\n",
    "Run this first. It connects directly to the absolute DuckDB file in `data/processed/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import duckdb\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "while repo_root != repo_root.parent and not (repo_root / 'ptn_analysis').exists():\n",
    "    repo_root = repo_root.parent\n",
    "if not (repo_root / 'ptn_analysis').exists():\n",
    "    raise RuntimeError('Could not find repo root containing ptn_analysis.')\n",
    "\n",
    "repo_root_str = str(repo_root)\n",
    "sys.path = [p for p in sys.path if p != repo_root_str]\n",
    "sys.path.insert(0, repo_root_str)\n",
    "\n",
    "absolute_db_path = (repo_root / 'data/processed/wpg_transit.duckdb').resolve()\n",
    "if not absolute_db_path.exists():\n",
    "    raise FileNotFoundError(f'DuckDB file missing: {absolute_db_path}. Run `make data`.')\n",
    "\n",
    "con = duckdb.connect(str(absolute_db_path))\n",
    "con.execute('INSTALL spatial; LOAD spatial;')\n",
    "\n",
    "print(f'DB path: {absolute_db_path}')\n",
    "database_connections = con.execute('PRAGMA database_list').fetchdf()\n",
    "database_connections = database_connections.rename(columns={\n",
    "    'seq': 'connection_sequence',\n",
    "    'name': 'database_alias',\n",
    "    'file': 'database_file_path',\n",
    "})\n",
    "display(database_connections)\n",
    "print('Connected file (full path):', database_connections.loc[0, 'database_file_path'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d6246",
   "metadata": {},
   "source": [
    "## 5) Data Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    ('raw_gtfs_stops', 'Transit Stops'),\n",
    "    ('raw_gtfs_routes', 'Routes'),\n",
    "    ('raw_gtfs_trips', 'Trips'),\n",
    "    ('raw_gtfs_stop_times', 'Stop Times'),\n",
    "    ('raw_gtfs_edges_weighted', 'Network Edges'),\n",
    "    ('raw_neighbourhoods', 'Neighbourhoods'),\n",
    "    ('raw_community_areas', 'Community Areas'),\n",
    "    ('raw_open_data_pass_ups', 'Pass-up Data'),\n",
    "    ('raw_open_data_on_time', 'On-time Data'),\n",
    "    ('raw_open_data_passenger_counts', 'Passenger Counts'),\n",
    "    ('agg_stops_per_neighbourhood', 'Coverage by Neighbourhood'),\n",
    "    ('agg_stops_per_community', 'Coverage by Community'),\n",
    "    ('agg_route_passups_summary', 'Route Pass-up Summary'),\n",
    "    ('agg_route_ontime_summary', 'Route On-time Summary'),\n",
    "    ('agg_stop_ontime_summary', 'Stop On-time Summary'),\n",
    "    ('ref_route_mapping', 'Route Mapping'),\n",
    "    ('ref_stop_mapping', 'Stop Mapping'),\n",
    "    ('v_route_performance', 'Route Performance View'),\n",
    "    ('v_stop_performance', 'Stop Performance View'),\n",
    "]\n",
    "\n",
    "print('=' * 56)\n",
    "print('DATA PIPELINE STATUS')\n",
    "print('=' * 56)\n",
    "\n",
    "for table, name in tables:\n",
    "    try:\n",
    "        count = con.execute(f'SELECT COUNT(*) FROM {table}').fetchone()[0]\n",
    "        print(f'{name:.<40} {count:>12,} rows')\n",
    "    except Exception:\n",
    "        print(f'{name:.<40} NOT LOADED')\n",
    "\n",
    "print('\\nTable prefix totals:')\n",
    "for prefix in ('raw_', 'agg_', 'ref_', 'v_'):\n",
    "    names = [\n",
    "        r[0] for r in con.execute(\n",
    "            \"SELECT table_name FROM information_schema.tables WHERE table_schema='main' AND table_name LIKE ? ORDER BY table_name\",\n",
    "            [f'{prefix}%']\n",
    "        ).fetchall()\n",
    "    ]\n",
    "    total_rows = 0\n",
    "    for table_name in names:\n",
    "        total_rows += con.execute(f'SELECT COUNT(*) FROM {table_name}').fetchone()[0]\n",
    "    print(f'  {prefix:<4} total rows (sum of table counts): {total_rows:,}')\n",
    "\n",
    "print('\\nTable counts by prefix:')\n",
    "for prefix in ('raw_', 'agg_', 'ref_', 'v_'):\n",
    "    table_count = con.execute(\n",
    "        \"SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='main' AND table_name LIKE ?\",\n",
    "        [f'{prefix}%']\n",
    "    ).fetchone()[0]\n",
    "    print(f'  {prefix:<4} tables: {table_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate feed date range\n",
    "try:\n",
    "    feed = con.execute('SELECT feed_start_date, feed_end_date FROM raw_gtfs_feed_info').fetchone()\n",
    "    if feed:\n",
    "        print(f'GTFS Feed Period: {feed[0]} to {feed[1]}')\n",
    "    else:\n",
    "        print('Feed info not loaded')\n",
    "except Exception:\n",
    "    print('Feed info not loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8b1b8",
   "metadata": {},
   "source": [
    "## 6) Frequency Analysis (Ahmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0824562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ptn_analysis.analysis.frequency as frequency_module\n",
    "\n",
    "importlib.reload(frequency_module)\n",
    "\n",
    "summary_stats = frequency_module.get_frequency_summary(con=con)\n",
    "print('Frequency Summary (Network-wide):')\n",
    "for metric_name, metric_value in summary_stats.items():\n",
    "    if isinstance(metric_value, float):\n",
    "        print(f'  {metric_name}: {metric_value:.2f}')\n",
    "    else:\n",
    "        print(f'  {metric_name}: {metric_value:,}')\n",
    "\n",
    "print('\\nTop 10 routes by trip departures:')\n",
    "route_frequency = frequency_module.compute_route_frequency(con=con).copy()\n",
    "route_frequency = route_frequency.rename(columns={\n",
    "    'route_id': 'gtfs_route_id',\n",
    "    'total_trips': 'total_trip_departures',\n",
    "    'peak_trips': 'peak_period_trip_departures',\n",
    "    'avg_headway_peak': 'peak_period_avg_headway_minutes',\n",
    "    'avg_headway_offpeak': 'midday_avg_headway_minutes',\n",
    "})\n",
    "route_frequency_columns = [\n",
    "    'route_name',\n",
    "    'gtfs_route_id',\n",
    "    'total_trip_departures',\n",
    "    'peak_period_trip_departures',\n",
    "    'peak_period_avg_headway_minutes',\n",
    "    'midday_avg_headway_minutes',\n",
    "    'service_span_hours',\n",
    "]\n",
    "available_route_frequency_columns = [column for column in route_frequency_columns if column in route_frequency.columns]\n",
    "display(route_frequency[available_route_frequency_columns].head(10))\n",
    "\n",
    "print('\\nHourly departure profile (all routes):')\n",
    "hourly_profile = frequency_module.get_hourly_profile(con=con).copy()\n",
    "hourly_profile = hourly_profile.rename(columns={'hour': 'service_hour', 'trip_count': 'trips_departing'})\n",
    "display(hourly_profile)\n",
    "\n",
    "print('\\nRoute direction labels (derived from trip headsign):')\n",
    "route_direction_labels = frequency_module.get_route_direction_labels(con=con).copy()\n",
    "route_direction_labels = route_direction_labels.rename(columns={'route_id': 'gtfs_route_id', 'direction_id': 'direction_code'})\n",
    "display(route_direction_labels.head(20))\n",
    "\n",
    "print('\\nTrips by route, direction, and service hour (sample):')\n",
    "trips_per_hour = frequency_module.compute_trips_per_hour(con=con).copy()\n",
    "trips_per_hour = trips_per_hour.rename(columns={\n",
    "    'route_id': 'gtfs_route_id',\n",
    "    'hour': 'service_hour',\n",
    "    'trip_count': 'trips_departing',\n",
    "    'direction_id': 'direction_code',\n",
    "})\n",
    "display(trips_per_hour.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfbb4a7",
   "metadata": {},
   "source": [
    "## 7) References\n",
    "\n",
    "- GTFS reference: https://gtfs.org/schedule/reference/\n",
    "- Winnipeg Open Data portal: https://data.winnipeg.ca\n",
    "- DuckDB docs: https://duckdb.org/docs/\n",
    "- Transitland terms: https://www.transit.land/terms\n",
    "\n",
    "---\n",
    "Prepared by: **Ahmed Hasan (7932883)**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}